2026-01-15 12:00:41,603 - __main__ - INFO - Starting Logistics Intelligence Radar...
2026-01-15 12:00:41,603 - config.llm_config - INFO - Attempting to connect to OpenAI (gpt-4o)...
[92m12:00:41 - LiteLLM:INFO[0m: utils.py:3748 - 
LiteLLM completion() model= gpt-4o; provider = openai
2026-01-15 12:00:41,613 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o; provider = openai
2026-01-15 12:00:42,200 - openai._base_client - INFO - Retrying request to /chat/completions in 0.490054 seconds
2026-01-15 12:00:43,018 - openai._base_client - INFO - Retrying request to /chat/completions in 0.816921 seconds
2026-01-15 12:00:44,167 - config.llm_config - WARNING - Failed to connect to OpenAI: litellm.RateLimitError: RateLimitError: OpenAIException - You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.
2026-01-15 12:00:44,167 - config.llm_config - INFO - Falling back to OpenRouter (openrouter/allenai/molmo-2-8b:free)...
[92m12:00:44 - LiteLLM:INFO[0m: utils.py:3748 - 
LiteLLM completion() model= liquid/lfm-40b:free; provider = openrouter
2026-01-15 12:00:44,170 - LiteLLM - INFO - 
LiteLLM completion() model= liquid/lfm-40b:free; provider = openrouter
2026-01-15 12:00:44,984 - config.llm_config - ERROR - Failed to connect to OpenRouter: litellm.NotFoundError: NotFoundError: OpenrouterException - {"error":{"message":"No endpoints found for liquid/lfm-40b:free.","code":404},"user_id":"user_38C7AvPoQHeTW5D6KBSxmr4IPlr"}
2026-01-15 12:00:44,985 - config.llm_config - CRITICAL - All LLM providers failed. Exiting application.
Fatal Error: Could not connect to any LLM provider.
